{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import os\n",
    "import zipfile\n",
    "import pickle as cPickle\n",
    "from scipy import stats\n",
    "\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/pl/active/icesheetsclimate/firn_iceshelves/deg0C/output/' #folder where SNOWPACK output is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ------- MAIN FUNCTION -------- ######\n",
    "#load all data for station and create a dictionary structure\n",
    "    #stn\n",
    "        #hist\n",
    "            #pro - profile data (depth, density, subsurface temperature, air, water, ice %)\n",
    "            #ts - smet timeseries data (cold content, air temp, windspeed, rainfall, sublimation, melt, freeze, snowfall)\n",
    "        #ssp1\n",
    "            #pro\n",
    "            #ts\n",
    "        #ssp3\n",
    "            #......\n",
    "def load_data(stn):\n",
    "    dc = {}\n",
    "    print('loading historical')\n",
    "    dc['hist'] = {}\n",
    "    pro, smet = read_zip_output_files(stn, 'HIST')\n",
    "    dc['hist']['pro'] = pro\n",
    "    dc['hist']['ts'] = smet\n",
    "\n",
    "    \n",
    "    return dc\n",
    "\n",
    "###### ---------------------------------------- ######\n",
    "\n",
    "#open zip files and load data from .smet and .pro files\n",
    "def read_zip_output_files(stn, a):\n",
    "    if a == 'HIST':\n",
    "        zz=f'{output_folder}HIST/{stn}.zip'\n",
    "        with zipfile.ZipFile(zz) as z:\n",
    "            files = z.namelist()\n",
    "            if f'output//{stn}.pro' in files:\n",
    "                profile = f'output//{stn}.pro'\n",
    "                smetfile = f'output//{stn}.smet'\n",
    "            elif f'output/{stn}.pro' in files:\n",
    "                profile = f'output/{stn}.pro'\n",
    "                smetfile = f'output/{stn}.smet'\n",
    "            else:\n",
    "                profile = f'{stn}.pro'\n",
    "                smetfile = f'{stn}.smet'\n",
    "    else:\n",
    "        zz = f'{output_folder}{a}/{stn}_{a}_output.zip'\n",
    "        profile = f'output/{stn}_{a}.pro'\n",
    "        smetfile = f'output/{stn}_{a}.smet'\n",
    "    with zipfile.ZipFile(zz) as z:\n",
    "        with z.open(profile, 'r') as p:\n",
    "            pro = load_pro_data(p)\n",
    "        with z.open(smetfile, 'r') as s: \n",
    "            smet = load_smet_data(s)\n",
    "            \n",
    "    return pro, smet\n",
    "\n",
    "#load data from .pro file\n",
    "def load_pro_data(f):\n",
    "    #important data codes from SNOWPACK output\n",
    "    #0500 = date\n",
    "    #0501 = height (cm)\n",
    "    #0502 = density (kg/m3)\n",
    "    #0503 = snow temperature\n",
    "    #0506 = volumetric water (%)\n",
    "    #0515 = volumetric ice (%)\n",
    "    #0516 = volumetric air (%)\n",
    "    \n",
    "    f.readline()#header\n",
    "    f.readline()#header\n",
    "    lat = f.readline() #latitude\n",
    "    lat = float(str(lat, 'utf-8').split(' ')[-1][:-2])\n",
    "    lon = f.readline() #longitude\n",
    "    lon = float(str(lon, 'utf-8').split(' ')[-1][:-2])\n",
    "\n",
    "    #more header lines\n",
    "    header = 'nnn'\n",
    "    while header != b'[DATA]\\n':\n",
    "        header = f.readline()\n",
    "        \n",
    "    all_data = list()\n",
    "    \n",
    "    for line in f:\n",
    "        line = str(line, 'utf-8')\n",
    "        if line[0:4] == '0500': # date\n",
    "            dd = line.split(',')[1].split('.')\n",
    "            dt = datetime.datetime(int(dd[2][0:4]), int(dd[1]), int(dd[0]), int(dd[2][5:7]))\n",
    "            year = dt.year\n",
    "            temp_data = {} #dictionary of data for each timestep\n",
    "            temp_data['date'] = dt\n",
    "        if year >= 1985:\n",
    "            if line[0:4] == '0501': # depth\n",
    "                temp_depth = list(map(float, line.split('\\n')[0].split(',')[2:]))\n",
    "                temp_depth = np.asarray(temp_depth)/100 #convert to meters\n",
    "                d = temp_depth + (100-temp_depth[-1]) #convert from height to depth\n",
    "                aa = np.argwhere(d < 0)\n",
    "                if len(aa > 1):\n",
    "                    a = aa[-1][0]+1\n",
    "                else:\n",
    "                    a = 0\n",
    "                temp_data['depth'] = d[a:]\n",
    "            elif line[0:4] == '0502': # density\n",
    "                temp_density = list(map(float, line.split('\\n')[0].split(',')[2:]))\n",
    "                temp_data['density'] = np.asarray(temp_density)[a:]\n",
    "            elif line[0:4] == '0516': # %air\n",
    "                temp_air = list(map(float, line.split('\\n')[0].split(',')[2:]))\n",
    "                temp_data['air'] = np.asarray(temp_air)[a:]/100\n",
    "            elif line[0:4] == '0517': # append to list\n",
    "                all_data.append(temp_data)\n",
    "            \n",
    "    return all_data\n",
    "        \n",
    "#load timeseries smet data\n",
    "def load_smet_data(f): \n",
    "     \n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    smet = pd.read_csv(f, delim_whitespace=True, skiprows=19, parse_dates=['time'], date_parser=dateparse,\n",
    "                           names = ['time', 'Qs', 'Ql', 'Qg', 'TSG', 'Qg0', 'Qr', 'Qmf', 'CC', 'OLWR', \n",
    "                            'ILWR', 'LWR_net', 'OSWR', 'ISWR', 'Qw', 'pAlbedo', 'mAlbedo', 'ISWR_h', 'ISWR_dir',\n",
    "                            'ISWR_diff', 'TA', 'TSS_mod', 'TSS_meas', 'T_bottom', 'RH', 'VW', 'VW_drift', 'DW',\n",
    "                            'MS_Snow', 'HS_mod', 'HS_meas', 'hoar_size', 'wind_trans24', 'HN24', 'HN72_24', 'SWE',\n",
    "                            'MS_Water', 'MS_Wind', 'rainfall', 'MS_SN_Runoff', 'MS_Soil_Runoff', 'sublimation',\n",
    "                            'MS_Evap', 'melt', 'freeze', 'MS_Sublimation_dHS', 'MS_Settling_dHS', 'MS_Redeposit_dHS',\n",
    "                            'MS_Redeposit_dRHO', 'Sclass1', 'Sclass2', 'zSd', 'Sd', 'zSn', 'Sn', 'zSs', 'Ss', 'zS4',\n",
    "                            'S4', 'zS5', 'S5'])\n",
    "    smet = smet[['time', 'TA', 'VW', 'MS_Snow', 'MS_Wind', 'rainfall', 'sublimation','melt', 'freeze']]\n",
    "    smet['snowfall'] = smet['MS_Snow'] - smet['MS_Wind']\n",
    "    smet = smet.drop(columns = ['MS_Snow', 'MS_Wind'])\n",
    "    \n",
    "    #convert from kg/m2/hr to kg/m2\n",
    "    smet['dt'] = (smet['time']-smet['time'].shift()).dt.total_seconds()/3600\n",
    "    smet['snowfall'] = smet['snowfall'] * smet['dt']\n",
    "    smet['rainfall'] = smet['rainfall'] * smet['dt']\n",
    "    smet = smet.drop(columns = ['dt'])\n",
    "    smet = smet[smet.time.dt.year >=1985]\n",
    "    return smet\n",
    "\n",
    "#write pickle file\n",
    "def write_pickle(stn, dc):\n",
    "    with open(f'/pl/active/icesheetsclimate/firn_iceshelves/deg0C/pickles/{stn}.p', 'wb') as fp:\n",
    "        cPickle.dump(dc, fp, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pickle files with historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = glob(f'{output_folder}HIST/*.zip')\n",
    "pickles = glob(f'/pl/active/icesheetsclimate/firn_iceshelves/deg0C/pickles/*')\n",
    "n = len(zip_files)\n",
    "i = 0\n",
    "\n",
    "for zz in zip_files:\n",
    "    \n",
    "    stn = zz.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    print(f'{i}/{n} {stn}')\n",
    "    if f'/pl/active/icesheetsclimate/firn_iceshelves/deg0C/pickles/{stn}.p' not in pickles:\n",
    "        df = load_data(stn)\n",
    "        write_pickle(stn, df)\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle_data(site):\n",
    "    site_file = f'/pl/active/icesheetsclimate/firn_iceshelves/deg0C/pickles/{site}.p'\n",
    "    with open(site_file, 'rb') as fp:\n",
    "        data = cPickle.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'ssp1'\n",
    "s2 = 'SSP1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIR116 1/1\n",
      "... loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59880/3442677984.py:110: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "for p in pickles:\n",
    "    stn = p.split('/')[-1][:-2]\n",
    "    print(stn, f'{n}/{len(pickles)}')\n",
    "    dc = get_pickle_data(stn)\n",
    "    \n",
    "    if scenario not in dc:\n",
    "        print('... loading')\n",
    "        dc[scenario] = {}\n",
    "        pro,smet = read_zip_output_files(stn, s2)\n",
    "        dc[scenario]['pro'] = pro\n",
    "        dc[scenario]['ts'] = smet\n",
    "        \n",
    "        write_pickle(stn, dc)\n",
    "    \n",
    "    \n",
    "    n = n+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firn_air_content",
   "language": "python",
   "name": "firn_air_content"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
